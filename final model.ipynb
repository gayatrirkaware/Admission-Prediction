{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f8a2ba-69e4-418d-b667-5267931fd511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "import keras_tuner as kt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22fed56-dcb7-4302-bcaf-04487573691a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33895300-4df3-454f-86fa-e316a21d37cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Admission_Predict_Ver1.1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b3b83ab-38c5-42d6-9079-0d39462ff13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc4f3a4-e835-4994-9d10-3287cc795fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa1323a2-cf62-4d85-9cb4-62bd7617c79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d340bc5f-86c8-44ea-9c76-2b03a67d82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Serial No.'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ff290d-a608-4bc2-8c13-3d371b427365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30fe6222-9258-4daf-9732-f1586e99e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9f498f-99a8-4897-9f83-91b79e8d4d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test ,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c38c15c-544d-457a-96c1-1f6257b235fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()\n",
    "x_train_scaled = scalar.fit_transform(x_train)\n",
    "x_test_scaled = scalar.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a06346db-2218-4758-9319-3bf49357bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "487579f3-a61d-4f12-807d-9aa6066766f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m8\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33756727-eb77-4bce-ac81-8abe75bcb0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16051381-1415-48d4-bda4-429fddc73f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.1189 - val_loss: 0.0897\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0828 - val_loss: 0.0722\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0659 - val_loss: 0.0581\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0562 - val_loss: 0.0453\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0473 - val_loss: 0.0353\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0343 - val_loss: 0.0290\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0289 - val_loss: 0.0254\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0236 - val_loss: 0.0227\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0241 - val_loss: 0.0210\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0191 - val_loss: 0.0199\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0193 - val_loss: 0.0183\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0154 - val_loss: 0.0153\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0156 - val_loss: 0.0141\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0145 - val_loss: 0.0133\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0141 - val_loss: 0.0125\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0128 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0119 - val_loss: 0.0107\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0104 - val_loss: 0.0098\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0087 - val_loss: 0.0086\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0093 - val_loss: 0.0079\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0039 - val_loss: 0.0043\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ed8c026-1c26-428f-9cc1-ad28abc24aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89fcb056-2a95-4924-9113-0859fc70bd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7712422916990479"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02e9ecd9-207e-4513-8512-042b6cc230eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12baaff1f10>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa45a903-f216-40f6-857c-f3e5aac4133b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "355eeef9-d412-4edf-b050-71074ab330c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 52s]\n",
      "val_loss: 0.0231510978192091\n",
      "\n",
      "Best val_loss So Far: 0.006448481697589159\n",
      "Total elapsed time: 00h 16m 11s\n",
      "Best Hyperparameters:\n",
      "\n",
      "{'units_1': 64, 'initializer_1': 'he_normal', 'lambda_reg_1': 0.0002946172832313487, 'activation_1': 'relu', 'dropout_1': 0.0, 'units_2': 8, 'initializer_2': 'glorot_uniform', 'lambda_reg_2': 0.00015210043470696266, 'activation_2': 'tanh', 'dropout_2': 0.4, 'units_3': 8, 'initializer_3': 'glorot_uniform', 'lambda_reg_3': 0.007543309296844701, 'activation_3': 'relu', 'dropout_3': 0.0, 'optimizer': 'adam', 'learning_rate': 0.0081}\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Hidden Layer 1\n",
    "    units_1 = hp.Int(\"units_1\", min_value=8, max_value=64, step=8)\n",
    "    initializer_1 = hp.Choice(\"initializer_1\", ['glorot_uniform', 'he_normal'])\n",
    "    lambda_reg_1 = hp.Float(\"lambda_reg_1\", min_value=0.0001, max_value=0.01, sampling='log')\n",
    "    model.add(Dense(units=units_1,\n",
    "                    kernel_initializer=initializer_1,\n",
    "                    kernel_regularizer=regularizers.l2(lambda_reg_1),\n",
    "                    input_dim=7))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    activation_1 = hp.Choice(\"activation_1\", ['relu', 'tanh'])\n",
    "    model.add(Activation(activation_1))\n",
    "    dropout_rate_1 = hp.Float('dropout_1', min_value=0.0, max_value=0.4, step=0.1)\n",
    "    model.add(Dropout(dropout_rate_1))\n",
    "\n",
    "    # Hidden Layer 2\n",
    "    units_2 = hp.Int(\"units_2\", min_value=8, max_value=32, step=8)\n",
    "    initializer_2 = hp.Choice(\"initializer_2\", ['glorot_uniform', 'he_normal'])\n",
    "    lambda_reg_2 = hp.Float(\"lambda_reg_2\", min_value=0.0001, max_value=0.01, sampling='log')\n",
    "    model.add(Dense(units=units_2,\n",
    "                    kernel_initializer=initializer_2,\n",
    "                    kernel_regularizer=regularizers.l2(lambda_reg_2)))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    activation_2 = hp.Choice(\"activation_2\", ['relu', 'tanh'])\n",
    "    model.add(Activation(activation_2))\n",
    "    dropout_rate_2 = hp.Float('dropout_2', min_value=0.0, max_value=0.4, step=0.1)\n",
    "    model.add(Dropout(dropout_rate_2))\n",
    "\n",
    "    # Hidden Layer 3\n",
    "    units_3 = hp.Int(\"units_3\", min_value=8, max_value=16, step=8)\n",
    "    initializer_3 = hp.Choice(\"initializer_3\", ['glorot_uniform', 'he_normal'])\n",
    "    lambda_reg_3 = hp.Float(\"lambda_reg_3\", min_value=0.0001, max_value=0.01, sampling='log')\n",
    "    model.add(Dense(units=units_3,\n",
    "                    kernel_initializer=initializer_3,\n",
    "                    kernel_regularizer=regularizers.l2(lambda_reg_3)))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    activation_3 = hp.Choice(\"activation_3\", ['relu', 'tanh'])\n",
    "    model.add(Activation(activation_3))\n",
    "    dropout_rate_3 = hp.Float('dropout_3', min_value=0.0, max_value=0.4, step=0.1)\n",
    "    model.add(Dropout(dropout_rate_3))\n",
    "\n",
    "    # Output Layer for Regression\n",
    "    model.add(Dense(units=1, activation='linear'))  # Linear output for regression\n",
    "\n",
    "    # Optimizers\n",
    "    optimizers_choice = hp.Choice(\"optimizer\", ['adam', 'sgd', 'rmsprop'])\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=0.0001, max_value=0.01, step=0.001)\n",
    "    if optimizers_choice == 'adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizers_choice == 'sgd':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizers_choice == 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='mean_squared_error',  # Regression loss\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mae'])  # You can also add 'mse', 'mape', etc.\n",
    "\n",
    "    return model\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner = kt.RandomSearch(build_model,\n",
    "                        max_trials=20,\n",
    "                        objective=\"val_loss\",\n",
    "                        executions_per_trial=1,\n",
    "                        directory='Results',\n",
    "                        project_name=\"My_Project_Regression 1\")\n",
    "\n",
    "tuner.search(x_train, y_train,\n",
    "             epochs=200,\n",
    "             validation_data=(x_test, y_test),\n",
    "             batch_size=32,\n",
    "             verbose=2)\n",
    "\n",
    "best_hyp = tuner.get_best_hyperparameters(1)[0]\n",
    "print(\"Best Hyperparameters:\\n\")\n",
    "print(best_hyp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33560fd9-3dea-447f-8c8b-8ccee5a1aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ae26f-b200-4ec1-80f2-38f5bb928860",
   "metadata": {},
   "source": [
    "### Best Model from Tuner and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "529a02c6-1a2f-42ec-985d-5821b21a0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"model\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "465abd44-5dfe-403d-8a41-0f1b8209dd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Get the best model from the tuner\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "best_model.save(\"model/best_regression_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab397a-ff83-45e9-a3f8-0761d8fcba91",
   "metadata": {},
   "source": [
    "### Predict on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33300a25-b371-4bea-9b32-e89f647df713",
   "metadata": {},
   "source": [
    "### Predict using the model directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "214aea07-953e-4604-ab3e-8efe8a035c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Predictions:\n",
      " [[0.6627792 ]\n",
      " [0.7026626 ]\n",
      " [0.87807393]\n",
      " [0.7176015 ]\n",
      " [0.78165245]\n",
      " [0.6545882 ]\n",
      " [0.7083343 ]\n",
      " [0.7130311 ]\n",
      " [0.763898  ]\n",
      " [0.69914836]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Show predictions\n",
    "print(\"Predictions:\\n\", predictions[:10])  # Print first 10 predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d7fda0-896c-4653-beac-13dfef899050",
   "metadata": {},
   "source": [
    "### Load and Predict later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1339b1ee-94a8-4e32-8995-3ccd5861c172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000012BC66DCFE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000012BC66DCFE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000012BC66DCFE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000012BC66DCFE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Predictions:\n",
      " [[0.6627792 ]\n",
      " [0.7026626 ]\n",
      " [0.87807393]\n",
      " [0.7176015 ]\n",
      " [0.78165245]\n",
      " [0.6545882 ]\n",
      " [0.7083343 ]\n",
      " [0.7130311 ]\n",
      " [0.763898  ]\n",
      " [0.69914836]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"model/best_regression_model.h5\")\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "print(\"Predictions:\\n\", predictions[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae521e5c-9a71-4343-b3a5-96d6ecfa9642",
   "metadata": {},
   "source": [
    "### Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a34c675-3aff-4fc5-b384-026c087dc045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0068 - mae: 0.0590 \n",
      "Test MSE: 0.0064, Test MAE: 0.0579\n"
     ]
    }
   ],
   "source": [
    "loss, mae = best_model.evaluate(x_test, y_test)\n",
    "print(f\"Test MSE: {loss:.4f}, Test MAE: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3487ae-e73c-4944-9555-db6c2302a91a",
   "metadata": {},
   "source": [
    "### Save Model and scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f13465aa-2220-4012-9d7e-f803161db9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/scaler.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "model.save(\"model/admission_model.h5\")\n",
    "\n",
    "# Save scaler\n",
    "import joblib\n",
    "joblib.dump(scalar, \"model/scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffae862d-21c5-4012-b445-d2a8d915a284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
